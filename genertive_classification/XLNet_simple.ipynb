{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 364
    },
    "id": "aUzQGX2ILqMK",
    "outputId": "866def90-256b-47d3-96e2-773b7e1db2ed",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/bash: pip: command not found\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 81
    },
    "id": "NwTHAUqXk7_B",
    "outputId": "9ef202b9-89a1-4ebe-c4be-1f4e2ba81c30",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "\n",
    "import torch\n",
    "from torch.nn import BCEWithLogitsLoss\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "from transformers import AdamW, XLNetTokenizer, XLNetModel, XLNetLMHeadModel, XLNetConfig\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm, trange\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 69
    },
    "id": "o4ZY1PcIlfKW",
    "outputId": "8db41c69-4e0e-4f9f-d93f-a70e15c84d40",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU Available: True\n",
      "Number of GPU Available: 1\n",
      "GPU: GeForce RTX 2070\n"
     ]
    }
   ],
   "source": [
    "print(\"GPU Available: {}\".format(torch.cuda.is_available()))\n",
    "n_gpu = torch.cuda.device_count()\n",
    "print(\"Number of GPU Available: {}\".format(n_gpu))\n",
    "print(\"GPU: {}\".format(torch.cuda.get_device_name(0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "vothBTEKll78",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "a2Xf8DAOl0XH",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('./data/small_train.csv', index_col='id')\n",
    "test = pd.read_csv('./data/small_test.csv', index_col='id')\n",
    "\n",
    "# train = pd.read_csv('./data/train.csv', index_col='id')\n",
    "# test = pd.read_csv('./data/test.csv', index_col='id')\n",
    "\n",
    "# train, _ = train_test_split(train, test_size=0.993, random_state=42)\n",
    "# test, _ = train_test_split(test, test_size=0.993, random_state=42)\n",
    "\n",
    "# train.to_csv('./data/small_train.csv')\n",
    "# train.to_csv('./data/small_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 238
    },
    "id": "A1CjLi8LdP1b",
    "outputId": "bf286511-5bd4-4cfe-8c00-b2d81daf47b1",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment_text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>a818c1bb0a2ecab6</th>\n",
       "      <td>\"\\n\\n haiti \\nhey, can you explain what the wi...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92647af04527a57d</th>\n",
       "      <td>I completely agree. Let's see if I can make it...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7d6cc99efbc1c92c</th>\n",
       "      <td>Dr Dan has IMO good idea on this conflict. I t...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203ce75ab36c8b2b</th>\n",
       "      <td>Hey Burgas00, why did you make that personal a...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>e1eb4f245dfacc5c</th>\n",
       "      <td>Tamerlan Tsarnaev cause of death\\nMost news me...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                       comment_text  toxic  \\\n",
       "id                                                                           \n",
       "a818c1bb0a2ecab6  \"\\n\\n haiti \\nhey, can you explain what the wi...      0   \n",
       "92647af04527a57d  I completely agree. Let's see if I can make it...      0   \n",
       "7d6cc99efbc1c92c  Dr Dan has IMO good idea on this conflict. I t...      0   \n",
       "203ce75ab36c8b2b  Hey Burgas00, why did you make that personal a...      0   \n",
       "e1eb4f245dfacc5c  Tamerlan Tsarnaev cause of death\\nMost news me...      0   \n",
       "\n",
       "                  severe_toxic  obscene  threat  insult  identity_hate  \n",
       "id                                                                      \n",
       "a818c1bb0a2ecab6             0        0       0       0              0  \n",
       "92647af04527a57d             0        0       0       0              0  \n",
       "7d6cc99efbc1c92c             0        0       0       0              0  \n",
       "203ce75ab36c8b2b             0        0       0       0              0  \n",
       "e1eb4f245dfacc5c             0        0       0       0              0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 238
    },
    "id": "QWX6qJg-dRcR",
    "outputId": "d95dcd26-6454-4f78-88f6-774537ddaeb6",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment_text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>a818c1bb0a2ecab6</th>\n",
       "      <td>\"\\n\\n haiti \\nhey, can you explain what the wi...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92647af04527a57d</th>\n",
       "      <td>I completely agree. Let's see if I can make it...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7d6cc99efbc1c92c</th>\n",
       "      <td>Dr Dan has IMO good idea on this conflict. I t...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203ce75ab36c8b2b</th>\n",
       "      <td>Hey Burgas00, why did you make that personal a...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>e1eb4f245dfacc5c</th>\n",
       "      <td>Tamerlan Tsarnaev cause of death\\nMost news me...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                       comment_text  toxic  \\\n",
       "id                                                                           \n",
       "a818c1bb0a2ecab6  \"\\n\\n haiti \\nhey, can you explain what the wi...      0   \n",
       "92647af04527a57d  I completely agree. Let's see if I can make it...      0   \n",
       "7d6cc99efbc1c92c  Dr Dan has IMO good idea on this conflict. I t...      0   \n",
       "203ce75ab36c8b2b  Hey Burgas00, why did you make that personal a...      0   \n",
       "e1eb4f245dfacc5c  Tamerlan Tsarnaev cause of death\\nMost news me...      0   \n",
       "\n",
       "                  severe_toxic  obscene  threat  insult  identity_hate  \n",
       "id                                                                      \n",
       "a818c1bb0a2ecab6             0        0       0       0              0  \n",
       "92647af04527a57d             0        0       0       0              0  \n",
       "7d6cc99efbc1c92c             0        0       0       0              0  \n",
       "203ce75ab36c8b2b             0        0       0       0              0  \n",
       "e1eb4f245dfacc5c             0        0       0       0              0  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "zz9OzE2TmSN1",
    "outputId": "d02ce230-08a6-4592-c48c-9781de701cf4",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1116, 7)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "oW3dJFOTMkq1",
    "outputId": "39b63161-cee2-4201-f6e2-dd2477173df6",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1116, 7)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "PTOd-qKQMyFO",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "tokenizer = XLNetTokenizer.from_pretrained('xlnet-base-cased', do_lower_case=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "D3Xq-qP54SiF",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "train_text_list = train[\"comment_text\"].values\n",
    "test_text_list = test[\"comment_text\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "ocveMTIfM5cP",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def tokenize_inputs(text_list, tokenizer, num_embeddings=512):\n",
    "    \"\"\"\n",
    "    Tokenizes the input text input into ids. Appends the appropriate special\n",
    "    characters to the end of the text to denote end of sentence. Truncate or pad\n",
    "    the appropriate sequence length.\n",
    "    \"\"\"\n",
    "    # tokenize the text, then truncate sequence to the desired length minus 2 for\n",
    "    # the 2 special characters\n",
    "    tokenized_texts = list(map(lambda t: tokenizer.tokenize(t)[:num_embeddings-2], text_list))\n",
    "    # convert tokenized text into numeric ids for the appropriate LM\n",
    "    input_ids = [tokenizer.convert_tokens_to_ids(x) for x in tokenized_texts]\n",
    "    # append special token \"<s>\" and </s> to end of sentence\n",
    "    input_ids = [tokenizer.build_inputs_with_special_tokens(x) for x in input_ids]\n",
    "    # pad sequences\n",
    "    input_ids = pad_sequences(input_ids, maxlen=num_embeddings, dtype=\"long\", truncating=\"post\", padding=\"post\")\n",
    "    return input_ids\n",
    "\n",
    "def create_attn_masks(input_ids):\n",
    "    \"\"\"\n",
    "    Create attention masks to tell model whether attention should be applied to\n",
    "    the input id tokens. Do not want to perform attention on padding tokens.\n",
    "    \"\"\"\n",
    "    # Create attention masks\n",
    "    attention_masks = []\n",
    "\n",
    "    # Create a mask of 1s for each token followed by 0s for padding\n",
    "    for seq in input_ids:\n",
    "        seq_mask = [float(i>0) for i in seq]\n",
    "        attention_masks.append(seq_mask)\n",
    "    return attention_masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 139
    },
    "id": "p2ZVLj_OM8sV",
    "outputId": "fee0fd4d-7bc2-4bec-ba91-2a1837882482",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# create input id tokens\n",
    "train_input_ids = tokenize_inputs(train_text_list, tokenizer, num_embeddings=250)\n",
    "test_input_ids = tokenize_inputs(test_text_list, tokenizer, num_embeddings=250)\n",
    "train_attention_masks = create_attn_masks(train_input_ids)\n",
    "test_attention_masks = create_attn_masks(test_input_ids)\n",
    "\n",
    "train[\"features\"] = train_input_ids.tolist()\n",
    "train[\"masks\"] = train_attention_masks\n",
    "\n",
    "test[\"features\"] = test_input_ids.tolist()\n",
    "test[\"masks\"] = test_attention_masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "H2A1pqzcN_Gr",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-14-fb23636bc21e>:18: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  train_masks = torch.tensor(train_masks, dtype=torch.long)\n",
      "<ipython-input-14-fb23636bc21e>:19: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  valid_masks = torch.tensor(valid_masks, dtype=torch.long)\n"
     ]
    }
   ],
   "source": [
    "train, valid = train_test_split(train, test_size=0.2, random_state=42)\n",
    "X_train = train[\"features\"].values.tolist()\n",
    "X_valid = valid[\"features\"].values.tolist()\n",
    "\n",
    "train_masks = train[\"masks\"].values.tolist()\n",
    "valid_masks = valid[\"masks\"].values.tolist()\n",
    "\n",
    "label_cols = [\"toxic\", \"severe_toxic\", \"obscene\", \"threat\", \"insult\", \"identity_hate\"]\n",
    "Y_train = train[label_cols].values.tolist()\n",
    "Y_valid = valid[label_cols].values.tolist()\n",
    "\n",
    "X_train = torch.tensor(X_train)\n",
    "X_valid = torch.tensor(X_valid)\n",
    "\n",
    "Y_train = torch.tensor(Y_train, dtype=torch.float32)\n",
    "Y_valid = torch.tensor(Y_valid, dtype=torch.float32)\n",
    "\n",
    "train_masks = torch.tensor(train_masks, dtype=torch.long)\n",
    "valid_masks = torch.tensor(valid_masks, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[   17,    12,   494,  ...,     0,     0,     0],\n",
       "        [   17,    12,   102,  ...,     0,     0,     0],\n",
       "        [  338,    19,    17,  ...,     0,     0,     0],\n",
       "        ...,\n",
       "        [20064,  1260,    28,  ...,    64,     4,     3],\n",
       "        [   17,   150,  4177,  ...,     0,     0,     0],\n",
       "        [   17,  2582,    19,  ...,     0,     0,     0]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GQUZkER-OCVE",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Create Dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "KMeaH6gbOHM1",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Select a batch size for training\n",
    "batch_size = 4\n",
    "\n",
    "train_data = TensorDataset(X_train, train_masks, Y_train)\n",
    "train_sampler = RandomSampler(train_data)\n",
    "train_dataloader = DataLoader(train_data,\\\n",
    "                              sampler=train_sampler,\\\n",
    "                              batch_size=batch_size)\n",
    "\n",
    "validation_data = TensorDataset(X_valid, valid_masks, Y_valid)\n",
    "validation_sampler = SequentialSampler(validation_data)\n",
    "validation_dataloader = DataLoader(validation_data,\\\n",
    "                                   sampler=validation_sampler,\\\n",
    "                                   batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "XCE_3AnLOPpI",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def train(model, num_epochs,\\\n",
    "          optimizer,\\\n",
    "          train_dataloader, valid_dataloader,\\\n",
    "          model_save_path,\\\n",
    "          train_loss_set=[], valid_loss_set = [],\\\n",
    "          lowest_eval_loss=None, start_epoch=0,\\\n",
    "          device=\"cpu\"\n",
    "          ):\n",
    "  \"\"\"\n",
    "  Train the model and save the model with the lowest validation loss\n",
    "  \"\"\"\n",
    "\n",
    "  model.to(device)\n",
    "\n",
    "  for i in range(num_epochs):\n",
    "    actual_epoch = start_epoch + i\n",
    "\n",
    "    model.train()\n",
    "    tr_loss = 0\n",
    "    num_train_samples = 0\n",
    "\n",
    "    for step, batch in enumerate(train_dataloader):\n",
    "      batch = tuple(t.to(device) for t in batch)\n",
    "      b_input_ids, b_input_mask, b_labels = batch\n",
    "      optimizer.zero_grad()\n",
    "      loss = model(b_input_ids, attention_mask=b_input_mask, labels=b_labels)\n",
    "      tr_loss += loss.item()\n",
    "      num_train_samples += b_labels.size(0)\n",
    "      loss.backward()\n",
    "      optimizer.step()\n",
    "\n",
    "    print('training_loss'+str(tr_loss/num_train_samples))\n",
    "    model.eval()\n",
    "\n",
    "    # Tracking variables \n",
    "    eval_loss = 0\n",
    "    num_eval_samples = 0\n",
    "\n",
    "    for batch in valid_dataloader:\n",
    "      batch = tuple(t.to(device) for t in batch)\n",
    "      b_input_ids, b_input_mask, b_labels = batch\n",
    "      with torch.no_grad():\n",
    "        # Forward pass, calculate validation loss\n",
    "        loss = model(b_input_ids, attention_mask=b_input_mask, labels=b_labels)\n",
    "        eval_loss += loss.item()\n",
    "        num_eval_samples += b_labels.size(0)\n",
    "\n",
    "    print('validation loss'+str(eval_loss/num_eval_samples))\n",
    "\n",
    "    \n",
    "\n",
    "  return model, train_loss_set, valid_loss_set\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "8VMI7VWpOKj0",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#config = XLNetConfig()\n",
    "        \n",
    "class XLNetForMultiLabelSequenceClassification(torch.nn.Module):\n",
    "  \n",
    "  def __init__(self, num_labels=2):\n",
    "    super(XLNetForMultiLabelSequenceClassification, self).__init__()\n",
    "    self.num_labels = num_labels\n",
    "    self.xlnet = XLNetModel.from_pretrained('xlnet-base-cased')\n",
    "    self.classifier = torch.nn.Linear(768, num_labels)\n",
    "\n",
    "    torch.nn.init.xavier_normal_(self.classifier.weight)\n",
    "\n",
    "  def forward(self, input_ids, token_type_ids=None,\\\n",
    "              attention_mask=None, labels=None):\n",
    "    # last hidden layer\n",
    "    last_hidden_state = self.xlnet(input_ids=input_ids,\\\n",
    "                                   attention_mask=attention_mask,\\\n",
    "                                   token_type_ids=token_type_ids)\n",
    "    # pool the outputs into a mean vector\n",
    "    mean_last_hidden_state = self.pool_hidden_state(last_hidden_state)\n",
    "    logits = self.classifier(mean_last_hidden_state)\n",
    "        \n",
    "    if labels is not None:\n",
    "      loss_fct = BCEWithLogitsLoss()\n",
    "      loss = loss_fct(logits.view(-1, self.num_labels),\\\n",
    "                      labels.view(-1, self.num_labels))\n",
    "      return loss\n",
    "    else:\n",
    "      return logits\n",
    "    \n",
    "  def freeze_xlnet_decoder(self):\n",
    "    \"\"\"\n",
    "    Freeze XLNet weight parameters. They will not be updated during training.\n",
    "    \"\"\"\n",
    "    for param in self.xlnet.parameters():\n",
    "      param.requires_grad = False\n",
    "    \n",
    "  def unfreeze_xlnet_decoder(self):\n",
    "    \"\"\"\n",
    "    Unfreeze XLNet weight parameters. They will be updated during training.\n",
    "    \"\"\"\n",
    "    for param in self.xlnet.parameters():\n",
    "      param.requires_grad = True\n",
    "    \n",
    "  def pool_hidden_state(self, last_hidden_state):\n",
    "    \"\"\"\n",
    "    Pool the output vectors into a single mean vector \n",
    "    \"\"\"\n",
    "    last_hidden_state = last_hidden_state[0]\n",
    "    mean_last_hidden_state = torch.mean(last_hidden_state, 1)\n",
    "    return mean_last_hidden_state\n",
    "    \n",
    "model = XLNetForMultiLabelSequenceClassification(num_labels=len(Y_train[0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "6QuSJxanOMRy",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "optimizer = AdamW(model.parameters(), lr=2e-5, weight_decay=0.01, correct_bias=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "pxCN5nLvOO2a",
    "outputId": "4937d68e-c611-4915-aba7-0b0f3f5e84dc",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "num_epochs=1\n",
    "\n",
    "cwd = os.getcwd()\n",
    "model_save_path = output_model_file = os.path.join(cwd, \"./Models/xlnet_toxic.bin\")\n",
    "model, train_loss_set, valid_loss_set = train(model=model,\\\n",
    "                                              num_epochs=num_epochs,\\\n",
    "                                              optimizer=optimizer,\\\n",
    "                                              train_dataloader=train_dataloader,\\\n",
    "                                              model_save_path=model_save_path,\\\n",
    "                                              valid_dataloader=validation_dataloader,\\\n",
    "                                              device=\"cuda\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "12PYfqX3QrE-",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "\n",
    "## Get Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ey9FMYJxQqGs",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def generate_predictions(model, df, num_labels, device=\"cpu\", batch_size=32):\n",
    "  num_iter = math.ceil(df.shape[0]/batch_size)\n",
    "  \n",
    "  pred_probs = np.array([]).reshape(0, num_labels)\n",
    "  \n",
    "  model.to(device)\n",
    "  model.eval()\n",
    "  \n",
    "  for i in range(num_iter):\n",
    "    df_subset = df.iloc[i*batch_size:(i+1)*batch_size,:]\n",
    "    X = df_subset[\"features\"].values.tolist()\n",
    "    masks = df_subset[\"masks\"].values.tolist()\n",
    "    X = torch.tensor(X)\n",
    "    masks = torch.tensor(masks, dtype=torch.long)\n",
    "    X = X.to(device)\n",
    "    masks = masks.to(device)\n",
    "    with torch.no_grad():\n",
    "      logits = model(input_ids=X, attention_mask=masks)\n",
    "      logits = logits.sigmoid().detach().cpu().numpy()\n",
    "      pred_probs = np.vstack([pred_probs, logits])\n",
    "  \n",
    "  return pred_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wo0YyAH6XGTh",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "num_labels = len(label_cols)\n",
    "pred_probs = generate_predictions(model, test, num_labels, device=\"cuda\", batch_size=32)\n",
    "pred_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uVAWKam2ado5",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "label_cols = [\"toxic\", \"severe_toxic\", \"obscene\", \"threat\", \"insult\", \"identity_hate\"]\n",
    "\n",
    "test[\"toxic\"] = pred_probs[:,0]\n",
    "test[\"severe_toxic\"] = pred_probs[:,1]\n",
    "test[\"obscene\"] = pred_probs[:,2]\n",
    "test[\"threat\"] = pred_probs[:,3]\n",
    "test[\"insult\"] = pred_probs[:,4]\n",
    "test[\"identity_hate\"] = pred_probs[:,5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 324
    },
    "id": "r_l6LVlX_R9J",
    "outputId": "b3c0b724-fd29-46b6-c518-91cd4405bd4c",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 293
    },
    "id": "dpE1pjPIAJGg",
    "outputId": "75425da7-37f8-4dd4-a21b-7d80278a19c3",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "test_to_csv = test.reset_index()\n",
    "test_to_csv.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mF95PeFM_rDh",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "cwd = os.getcwd()\n",
    "pred_save_path = output_model_file = os.path.join(cwd, \"./Data/toxic_1_epoch_small.csv\")\n",
    "test_to_csv[[\"id\", \"toxic\", \"severe_toxic\", \"obscene\", \"threat\", \"insult\", \"identity_hate\"]].to_csv(pred_save_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tBnRrhxrjlEj",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "np.round(pred_probs)\n",
    "# pred_probs"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "XLNet_toxic_comment_classification_challenge_share.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}